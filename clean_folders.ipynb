{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import frontmatter\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "#------------------BEGIN HACKY --------------\n",
    "_mapping_tag = yaml.resolver.BaseResolver.DEFAULT_MAPPING_TAG\n",
    "\n",
    "def dict_representer(dumper, data):\n",
    "    return dumper.represent_dict(data.items())\n",
    "\n",
    "def dict_constructor(loader, node):\n",
    "    loader.flatten_mapping(node)\n",
    "    return collections.OrderedDict(loader.construct_pairs(node))\n",
    "\n",
    "def null_representer(dumper, value):\n",
    "    return dumper.represent_scalar(u'tag:yaml.org,2002:null', '')\n",
    "\n",
    "try:\n",
    "    yaml.CSafeDumper.add_representer(collections.OrderedDict, dict_representer)\n",
    "    yaml.CSafeDumper.add_representer(type(None), null_representer)\n",
    "except (AttributeError, ImportError):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "yaml.SafeDumper.add_representer(collections.OrderedDict, dict_representer)\n",
    "yaml.SafeDumper.add_representer(type(None), null_representer)\n",
    "yaml.SafeLoader.add_constructor(_mapping_tag, dict_constructor)\n",
    "\n",
    "#------------------END HACKY --------------\n",
    "\n",
    "\n",
    "content = glob.glob('content/**/*.md')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ntpath' has no attribute 'exist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[130], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#print('FILE:', source_image, '->', target_image)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m#print('URL:', source_image_url, '->', target_image_url)\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexist\u001b[49m(source_image):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath does not exist\u001b[39m\u001b[38;5;124m'\u001b[39m, source_image)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'ntpath' has no attribute 'exist'"
     ]
    }
   ],
   "source": [
    "\n",
    "for sourcefile in content:\n",
    "    basename = os.path.basename(sourcefile)\n",
    "    if basename == '_index.md':\n",
    "        continue\n",
    "    post = frontmatter.load(sourcefile)\n",
    "    year = post.metadata['date'].year\n",
    "    targetfolder = re.findall(r'^(\\w+[/\\\\]\\w+)',os.path.dirname(sourcefile))[0] \n",
    "    targetfolder = os.path.join(targetfolder,f'{year:.0f}')\n",
    "    targetfile = os.path.join(targetfolder,basename)\n",
    "    #print(targetfile,sourcefile)\n",
    "    post.metadata = collections.OrderedDict(post.metadata)\n",
    "    post.metadata.move_to_end('title', last=False)\n",
    "    #then reverse\n",
    "    \n",
    "    os.makedirs(targetfolder, exist_ok=True)\n",
    "\n",
    "    banner = post.metadata['banner']\n",
    "    images = re.findall(r'!\\[[^\\]]*\\]\\((.*?)\\s*(\"(?:.*[^\"])\")?\\s*\\)',post.content) #https://stackoverflow.com/questions/44227270/regex-to-parse-image-link-in-markdown\n",
    "    images.append((banner,\"\"))\n",
    "\n",
    "    outputpost = frontmatter.dumps(post)\n",
    "    for source_image_url,optionaltxt in images:\n",
    "        target_image = os.path.join(targetfolder, os.path.basename(source_image_url))\n",
    "        target_image_url = target_image.replace('\\\\','/').replace('content','')\n",
    "        if source_image_url[0]=='/':\n",
    "            source_image = os.path.join('static',source_image_url[1:])\n",
    "        else:\n",
    "            print('NOT MOVING',source_image_url)\n",
    "            continue\n",
    "        #print('FILE:', source_image, '->', target_image)\n",
    "        #print('URL:', source_image_url, '->', target_image_url)\n",
    "\n",
    "        if not os.path.exists(source_image):\n",
    "            print('path does not exist', source_image)\n",
    "            continue\n",
    "\n",
    "        outputpost = outputpost.replace(source_image_url,target_image_url)\n",
    "        \n",
    "        os.rename(source_image,target_image)\n",
    "\n",
    "    os.remove(sourcefile)\n",
    "    with open(targetfile, \"w\") as text_file:\n",
    "        text_file.write(outputpost)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #if len(images)>4:\n",
    "    #    break\n",
    "\n",
    "    #orig_bannerimg = \n",
    "    #print()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- title: Return period of Boulder 2013 extreme rain date: 2013-11-20\n",
      "01:30:00+00:00 author: aslak banner: XXXXXXXXXXXXXXXXXX aliases: -\n",
      "/2013/11/20/return-period-of-boulder-2013-extreme-rain/ -\n",
      "/Home/Miscellaneous-Debris/returnperiodofboulder2013extremerain ---\n",
      "!![](XXXXXXXXXXXXXXXXXX)Several media stories on the Colorado floods\n",
      "talk of it as a 1000-year flood. However, the original source of this\n",
      "claim was talking about a 1000-year precip event (not the same as a\n",
      "flood-event). Pielke Jr discusses this on [his\n",
      "blog](http://rogerpielkejr.blogspot.dk/2013/09/how-fantasy-becomes-\n",
      "fact.html?m=1). <!--more--> The source for the 1000-year return level\n",
      "estimates appears to be this [NOAA](http://hdsc.nws.noaa.gov/hdsc/pfds\n",
      "/pfds_map_cont.html?bkmrk=co) page. We can argue about how solid these\n",
      "very rare return levels are as they obviously must be based on an\n",
      "extrapolation beyond the largest recorded event. Nevertheless out of\n",
      "curiosity I looked up what return period NOAA estimated for the\n",
      "observed rainfalls.  I found this map of weekly rain totals and\n",
      "clicked on a gauge in Boulder. It received 12.91 inches over 1 week.\n",
      "Other neighboring gauges experienced similar amounts.  I then went to\n",
      "the NOAA [return-period/return\n",
      "level](http://hdsc.nws.noaa.gov/hdsc/pfds/pfds_map_cont.html?bkmrk=co)\n",
      "page and plugged in the lat lon of the station and got this return\n",
      "level plot for 7-day totals:  ![](XXXXXXXXXXXXXXXXXX)  From that\n",
      "return level graph the rainfall appears to be inconsistent with\n",
      "anything less than a 500-year event and the best estimate is that it\n",
      "is more rare than a 1000 year event. But again estimating the return\n",
      "period for this precipitation event is extrapolating far beyond past\n",
      "records and we should take it with a grain of salt. I would not go as\n",
      "far as calling it [pure\n",
      "fantasy](http://rogerpielkejr.blogspot.dk/2013/09/how-fantasy-becomes-\n",
      "fact.html) however.  Once the return period estimates are updated with\n",
      "the new observed precipitation extreme then the odds must shorten. Now\n",
      "that we have seen that it can happen then it will no longer seem quite\n",
      "as unlikely that it might happen again.  I have also downloaded\n",
      "Boulder precip data from\n",
      "[here](http://www.esrl.noaa.gov/psd/boulder/data.daily.html) and\n",
      "calculated my own empirical return period plot (see below). From this\n",
      "we clearly see that 12.91in is really off the scale. Prior to\n",
      "observing this extreme event you would probably have estimated a 1000\n",
      "year return period (as indeed NOAA appears to have done). (shading is\n",
      "1sigma).  ![](XXXXXXXXXXXXXXXXXX)  **Discharge in Boulder creek**\n",
      "![](XXXXXXXXXXXXXXXXXX)  It would also be interesting to see how the\n",
      "weekly discharge in Boulder Creek compares to the past. At this [stati\n",
      "on](http://waterdata.usgs.gov/nwis/uv?cb_00060=on&format=gif_default&p\n",
      "eriod=&begin_date=2013-09-11&end_date=2013-09-21&site_no=06730200) I\n",
      "get the weekly discharge (starting the 11th sept 2013) to be: 1.42bn\n",
      "feet<sup>3</sup> = 40M m<sup>3</sup>. A historical record can be found\n",
      "[here](http://waterdata.usgs.gov/co/nwis/dv?cb_00060=on&format=rdb&per\n",
      "iod=&begin_date=1986-10-01&end_date=2013-09-\n",
      "19&site_no=06730200&referred_module=sw) (since 1986). Taking this\n",
      "record, and stacking into weekly bins and looking at empirical return\n",
      "periods then I get the plot on the right. (shading is 1sigma /\n",
      "17-83%). There the 2013 event comes out to be a ~25-year event\n",
      "(unsurprisingly since it has been observed once in a record starting\n",
      "in 1986). But you can also notice that the 2013 event does not diverge\n",
      "from a straight line extrapolation of the more common events. I.e. you\n",
      "would/should probably have expected a ~25 year return period prior to\n",
      "the 2013 floods.  **Detail**:  Why do i look weekly discharge rather\n",
      "than flood levels? The reason is that flood levels and instantaneous\n",
      "discharge are very sensitive to changes in infrastructure and\n",
      "adaptation/protective measures (e.g. flood plains). Weekly discharge\n",
      "is much less sensitive to such changes. Return period confidence\n",
      "intervals have been calculated using the approach described in the\n",
      "supplementary info to [this paper]({{< ref\n",
      "\"publication/2013-10-11-homogeneous-record-of-atlantic-hurricane-\n",
      "surge-threat-since-1923.md\" >}}).\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function OrderedDict.__reversed__>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "YAMLHandler.export() missing 1 required positional argument: 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: YAMLHandler.export() missing 1 required positional argument: 'metadata'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "post = frontmatter.load(sourcefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/2010/02/sia.jpg'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.metadata['banner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
